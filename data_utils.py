import pandas as pd
import matplotlib.pyplot as plt
from matplotlib.patches import Patch
from IPython.display import display
from typing import List

def analyze_missing_values(df: pd.DataFrame) -> pd.DataFrame:
    """
    Analyse les valeurs manquantes dans un DataFrame.
    
    Args:
        df (pd.DataFrame): Le DataFrame √† analyser.
    
    Returns:
        pd.DataFrame: DataFrame avec les statistiques de valeurs manquantes par colonne.
    """
    # Pourcentage global de cellules vides
    total_cells = df.shape[0] * df.shape[1]
    missing_cells = df.isna().sum().sum()
    pct_missing_global = (missing_cells / total_cells) * 100
    
    print(f"\nüåê Pourcentage de cellules vides sur tout le DataFrame : {pct_missing_global:.2f}%")
    
    # Pourcentage par colonne
    missing_by_column = df.isna().sum()
    pct_by_column = (missing_by_column / len(df)) * 100
    
    # Cr√©er un DataFrame pour les statistiques
    missing_df = pd.DataFrame({
        'Colonne': df.columns,
        'Valeurs manquantes': missing_by_column.values,
        'Pourcentage (%)': pct_by_column.values
    })
    
    # Trier par pourcentage d√©croissant
    missing_df = missing_df.sort_values('Pourcentage (%)', ascending=False)

    return missing_df


def plot_missing_values(missing_df: pd.DataFrame, top_n: int = 15, min_threshold: float = 0.1):
    """
    Visualise les valeurs manquantes sous forme de graphique √† barres horizontales.
    
    Args:
        missing_df (pd.DataFrame): DataFrame retourn√© par analyze_missing_values().
        top_n (int): Nombre maximum de colonnes √† afficher (par d√©faut: 15).
        min_threshold (float): Pourcentage minimum pour afficher une colonne (par d√©faut: 0.1%).
    """
    # Filtrer les colonnes selon le seuil
    missing_cols = missing_df[missing_df['Pourcentage (%)'] >= min_threshold].head(top_n).copy()
    
    if len(missing_cols) > 0:
        fig, ax = plt.subplots(figsize=(14, max(6, len(missing_cols) * 0.4)))
        
        # Cr√©er le graphique horizontal
        bars = ax.barh(range(len(missing_cols)), missing_cols['Pourcentage (%)'])
        ax.set_yticks(range(len(missing_cols)))
        ax.set_yticklabels(missing_cols['Colonne'], fontsize=10)
        ax.set_xlabel('Pourcentage de valeurs manquantes (%)', fontsize=12, fontweight='bold')
        ax.set_title('Principales colonnes avec valeurs manquantes', fontsize=14, fontweight='bold', pad=20)
        ax.grid(axis='x', alpha=0.3, linestyle='--')
        
        # Colorer les barres selon le niveau de gravit√©
        colors = ['#2ecc71' if x < 1 else '#f39c12' if x < 5 else '#e74c3c' 
                  for x in missing_cols['Pourcentage (%)']]
        for bar, color in zip(bars, colors):
            bar.set_color(color)
        
        # Ajouter les valeurs sur les barres
        for i, (idx, row) in enumerate(missing_cols.iterrows()):
            ax.text(row['Pourcentage (%)'] + 0.5, i, f"{row['Pourcentage (%)']:.2f}%", 
                    va='center', fontsize=9, fontweight='bold')
        
        legend_elements = [
            Patch(facecolor='#2ecc71', label='< 1% manquant (excellente couverture)'),
            Patch(facecolor='#f39c12', label='1-5% manquant (bonne couverture)'),
            Patch(facecolor='#e74c3c', label='> 5% manquant (attention requise)')
        ]
        ax.legend(handles=legend_elements, loc='upper right', fontsize=9)
        
        # Ajuster les marges pour √©viter les warnings
        plt.subplots_adjust(left=0.25, right=0.95, top=0.95, bottom=0.1)
        plt.show()
    else:
        print(f"‚úÖ Aucune colonne avec ‚â• {min_threshold}% de valeurs manquantes !")


def split_ml_columns(
    df: pd.DataFrame,
    force_qualitative=None,
    force_ordinal=None,
    drop_cols=None,
    low_card_threshold=15
):
    """
    S√©paration des colonnes pour pipeline ML avec distinction ordinal/cat√©goriel
    
    Parameters:
    -----------
    force_qualitative : list, optional
        Colonnes √† forcer en cat√©goriel nominal
    force_ordinal : list, optional
        Colonnes √† forcer en ordinal (ex: notes, satisfactions)
    low_card_threshold : int
        Seuil de cardinalit√© pour sugg√©rer un type ordinal
    """
    
    force_qualitative = force_qualitative or []
    force_ordinal = force_ordinal or []
    drop_cols = drop_cols or []

    # Num√©riques
    numeric_cols = df.select_dtypes(include="number").columns.tolist()

    # Datetime
    datetime_cols = df.select_dtypes(include="datetime").columns.tolist()

    # Cat√©gorielles naturelles (nominal)
    categorical_cols = df.select_dtypes(
        include=["object", "category", "bool"]
    ).columns.tolist()

    # Num√©riques √† faible cardinalit√© ‚Üí ORDINAL potentiel
    low_card_numeric = [
        col for col in numeric_cols
        if df[col].nunique() <= low_card_threshold
        and col not in force_qualitative
    ]

    # Classification finale
    ordinal = sorted(set(low_card_numeric + force_ordinal) - set(drop_cols))
    
    qualitative = sorted(
        set(categorical_cols + force_qualitative) - set(ordinal) - set(drop_cols)
    )
    
    quantitative = sorted([
        col for col in numeric_cols
        if col not in ordinal 
        and col not in qualitative 
        and col not in drop_cols
    ])

    return {
        "quantitative": quantitative,
        "qualitative": qualitative,
        "ordinal": ordinal,
        "datetime": sorted(datetime_cols),
        "drop": drop_cols
    }

def check_duplicates(df: pd.DataFrame, subset=None):
    """
    V√©rifie les doublons dans un DataFrame.
    """

    total_rows = len(df)
    duplicate_rows = df.duplicated(subset=subset).sum()

    return {
        "subset": subset if subset is not None else "all_columns",
        "total_rows": total_rows,
        "duplicate_rows": duplicate_rows,
        "duplicate_ratio": duplicate_rows / total_rows if total_rows > 0 else 0
    }




def explore_dataframe(df: pd.DataFrame, show_missing: bool=True):
    """
    Affiche les informations principales d'un DataFrame :
    - shape
    - head
    - info
    - describe
    - statistiques de valeurs manquantes

    Parameters
    ----------
    df : pandas.DataFrame
        DataFrame √† analyser
    show_missing : bool, optional
        Affiche l'analyse des valeurs manquantes (default=True)
    """
    print("üìã INFORMATIONS G√âN√âRALES")
    print(f"‚Ä¢ Lignes    : {df.shape[0]}")
    print(f"‚Ä¢ Colonnes : {df.shape[1]}")

    print("\n--- INFO ---")
    df.info()
    
    print("\n--- DESCRIBE ---")
    display(df.describe())

    print("\n--- MISSING VALUES ---")
    missing_stats = analyze_missing_values(df)
    if show_missing:
        display(missing_stats)

    col_types = split_ml_columns(df)
    print("\n=== CLASSIFICATION DES VARIABLES ===")
    for k, v in col_types.items():
        print(f"{k.upper():<12} ({len(v)}): {v}")

    dup_info = check_duplicates(df)
    print("\n=== DUPLICATES ===")
    print(f"Lignes totales  : {dup_info['total_rows']}")
    print(f"Lignes dupliqu√©es: {dup_info['duplicate_rows']}")
    print(f"Taux            : {dup_info['duplicate_ratio']:.2%}")



def distribution_column(
    df: pd.DataFrame, 
    column: str, 
    showtitle: bool = True, 
    max_rows: int = 20
) -> None:
    """
    Affiche la distribution des valeurs d'une colonne.
    
    Args:
        df: DataFrame pandas
        column: Nom de la colonne
        showtitle: Afficher le titre (d√©faut: True)
        max_rows: Nombre maximum de lignes √† afficher (d√©faut: 20)
    """
    if showtitle:
        print(f"\nüìä Distribution de la colonne '{column}'")
        print("-" * 100)
    
    value_counts = df[column].value_counts(dropna=False)
    value_pct = (value_counts / len(df)) * 100
    
    distribution_summary = pd.DataFrame({
        'Effectif': value_counts,
        'Pourcentage': value_pct.round(2)
    })
    
    if len(distribution_summary) > max_rows:
        print(f"‚îÇ  ‚ÑπÔ∏è  Affichage des {max_rows} valeurs les plus fr√©quentes (total: {len(distribution_summary)})")
        display(distribution_summary.head(max_rows))
    else:
        display(distribution_summary)


def display_single_column_info(
    df: pd.DataFrame, 
    col: str, 
    show_distribution: bool = False,
    max_distribution_rows: int = 10
) -> None:
    """Affiche un r√©sum√© descriptif et visuel d'une seule colonne.
    
    Args:
        df: DataFrame pandas
        col: Nom de la colonne √† analyser
        show_distribution: Afficher la distribution d√©taill√©e (d√©faut: False)
        max_distribution_rows: Limite pour l'affichage de distribution (d√©faut: 10)
    """
    
    total_rows = len(df)
    
    if col not in df.columns:
        print(f"‚îå‚îÄ {col}")
        print("‚îÇ  ‚ùå Colonne inexistante")
        print("‚îî" + "‚îÄ" * 78)
        print()
        return

    series = df[col]
    n_unique = series.nunique(dropna=True)
    n_missing = series.isna().sum()
    pct_unique = n_unique / total_rows * 100
    pct_missing = n_missing / total_rows * 100

    # En-t√™te
    print(f"‚îå‚îÄ {col}")
    print("‚îÇ")

    # Type
    if pd.api.types.is_numeric_dtype(series):
        type_emoji = "üî¢"
    elif pd.api.types.is_datetime64_any_dtype(series):
        type_emoji = "üìÖ"
    else:
        type_emoji = "üî§"

    print(f"‚îÇ  {type_emoji} Type: {series.dtype}")
    print(f"‚îÇ  üéØ Uniques: {n_unique:,} ({pct_unique:.1f}%)")

    # Valeurs manquantes
    if n_missing > 0:
        print(f"‚îÇ  ‚ö†Ô∏è Manquantes: {n_missing:,} ({pct_missing:.1f}%)")
    else:
        print("‚îÇ  ‚úÖ Manquantes: 0 (0.0%)")

    # Valeurs explicites si peu nombreuses
    if 0 < n_unique <= 10:
        values = series.dropna().unique()
        values_str = ", ".join(map(str, values))
        if len(values_str) > 60:
            values_str = values_str[:60] + "..."
        print(f"‚îÇ  üìã Valeurs: {values_str}")

    # Statistiques num√©riques
    if pd.api.types.is_numeric_dtype(series) and n_unique > 10:
        min_val = series.min()
        max_val = series.max()
        mean_val = series.mean()
        mean_str = f"{mean_val:.2f}" if pd.notna(mean_val) else "N/A"
        print(f"‚îÇ  üìà Min: {min_val:.2f} | Max: {max_val:.2f} | Moyenne: {mean_str}")
    
    # Distribution d√©taill√©e (optionnelle et conditionnelle)
    if show_distribution and n_unique <= max_distribution_rows:
        print("‚îÇ")
        distribution_column(df, col, showtitle=False, max_rows=max_distribution_rows)
    
    print("‚îî" + "‚îÄ" * 78)
    print()

def remove_columns(
    df: pd.DataFrame, 
    columns: List[str], 
    verbose: bool = True,
    strict: bool = False
) -> pd.DataFrame:
    """
    Supprime les colonnes sp√©cifi√©es du DataFrame.

    Args:
        df: Le DataFrame d'origine
        columns: Liste des noms de colonnes √† supprimer
        verbose: Afficher les messages de progression (d√©faut: True)
        strict: Si True, l√®ve une erreur si une colonne n'existe pas (d√©faut: False)

    Returns:
        pd.DataFrame: Le DataFrame sans les colonnes supprim√©es
        
    Raises:
        KeyError: Si strict=True et qu'une colonne n'existe pas
    """
    if not columns:
        if verbose:
            print("‚ö†Ô∏è Aucune colonne √† supprimer")
        return df
    
    if verbose:
        print(f"üóÇÔ∏è Suppression de colonnes | shape initiale : {df.shape}")
    
    df = df.copy()
    
    # Colonnes r√©ellement pr√©sentes
    existing_cols = [col for col in columns if col in df.columns]
    missing_cols = [col for col in columns if col not in df.columns]
    
    # Mode strict : lever une erreur si colonne manquante
    if strict and missing_cols:
        raise KeyError(f"Colonnes inexistantes : {missing_cols}")
    
    # Supprimer les colonnes existantes
    if existing_cols:
        df = df.drop(columns=existing_cols)
    
    # Affichage des r√©sultats
    if verbose:
        if missing_cols:
            print(f"‚ö†Ô∏è Colonnes inexistantes (ignor√©es) : {missing_cols}")
        
        nb_supprimees = len(existing_cols)
        nb_ignorees = len(missing_cols)
        
        colonne_txt = "colonne" + ("s" if nb_supprimees > 1 else "")
        supprimee_txt = "supprim√©e" + ("s" if nb_supprimees > 1 else "")
        
        print(
            f"‚úÖ {nb_supprimees} {colonne_txt} {supprimee_txt} | "
            f"{nb_ignorees} inexistante{'s' if nb_ignorees > 1 else ''} | "
            f"shape finale : {df.shape}"
        )
    
    return df


def compare_group_means(
	df: pd.DataFrame,
	target_col: str, 
	quanti_cols: list[str], 
	group_labels: dict[int | str, str] | None = None, 
	sort_by_gap: bool = True,
	decimals: int = 2
) -> pd.DataFrame:
    """
    Compare les moyennes de variables quantitatives entre groupes d√©finis par une variable cible.
    
    Parameters
    ----------
    df : pd.DataFrame
        DataFrame contenant les donn√©es
    target_col : str
        Nom de la colonne cible (variable de groupement)
    quanti_cols : list
        Liste des colonnes quantitatives √† comparer
    group_labels : dict, optional
        Dictionnaire pour renommer les groupes {valeur_originale: nouveau_label}
        Ex: {0: 'Rest√©s (Non)', 1: 'Partis (Oui)'}
    sort_by_gap : bool, default=True
        Si True, trie les r√©sultats par √©cart absolu d√©croissant
    decimales : int, default=2
        Nombre de d√©cimales pour l'arrondi final
    
    Returns
    -------
    pd.DataFrame
        DataFrame avec les moyennes par groupe et l'√©cart en %
    """
    # Calculer les moyennes par groupe
    comparison = df.groupby(target_col)[quanti_cols].mean().T
    
    # Renommer les colonnes si labels fournis
    if group_labels:
        comparison.columns = [group_labels.get(col, col) for col in comparison.columns]
    
    # Calculer l'√©cart en % entre les deux groupes (suppose 2 groupes)
    cols = comparison.columns
    comparison['√âcart (%)'] = (
        (comparison[cols[1]] - comparison[cols[0]]) / comparison[cols[0]] * 100
    ).round(1)
    
    # Trier par √©cart absolu si demand√©
    if sort_by_gap:
        comparison = comparison.sort_values('√âcart (%)', key=abs, ascending=False)
    
    # Arrondir le r√©sultat final
    return comparison.round(decimals)